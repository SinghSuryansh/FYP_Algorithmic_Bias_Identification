{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.models.keyedvectors as word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the models:\n",
    "fname = \"C:/Users/Suryansh/Desktop/ucd/Stage4/FYP/New/Semester2/Word2vec_visualise/Models/bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.keyedvectors.KeyedVectors.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size = len(model.wv.vocab)-1\n",
    "w2v = np.zeros((max_size,model.layer1_size))\n",
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_dict = ['african','africans','black','blacks','chief','chiefs','coloured','kaffir','kaffer','cafri','locals','macaca','macaque','mulatto','mulattoes','native','negress','negro','negroes','nigger','pickaninny','pygmy','pygmies','savage','savages','slave','slaves','ewe','dogon','dinka','danakil','adali','odali','abyssinians','asante','berbers','amazighs','maasai','pahouin','san','somalis','somali','sudanese','sudan','gambian','gambia','algeria','algerian','angola','angolan','benin','beninese','camerron','cameroonian','chad','chadian','comoros','comoran','egypt','egyptian','eritrea','eritrean','ethiopia','ethiopian','gabon','gabonese','ghana','ghanian','liberia','liberian','libya','libyan','madagascar','madagascan','malawi','malawian','mali','malian','mauritania','mauretanian','mauritius','mauritian','morocco','moroccan','mozambique','mozambiquean','niger','nigerian','senegal','senegalese','seychelles','seychellois','swaziland','swazi','togo','togolese','tunisia','tunisian','uganda','ugandan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_dict = ['india','indian','indians','assamese','bengali','bhil','dhivehi','dogra','garhwali','gujarati','kutchi','hindavi','awadhi','bhojpuri','rajasthanis','marwaris','magahi','muhajirs','magahi','nagpuri','kashmiri','khas','konkani','kumaoni','maithils','marathi','odia','punjabi','pahari','parsi','rohingya','sindhi','memons','saraiki','saurashtra','sinhalese','sylheti','tharu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brit_dict = [\"brit\",\"brits\",\"british\",\"britisher\",\"britishers\",\"english\",\"englishman\",\"englishmen\",\"european\",\"europeans\",\"white\",\"whites\",\"american\",\"americans\",\"scotch\",\"scotchman\",\"irish\",\"irishman\",\"german\",\"germans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crim_dict = [\"criminal\",\"criminals\",\"offense\",\"offender\",\"lewd\",\"fraud\",\"abuse\",\"assailant\",\"assault\",\"bribe\",\"bribery\",\"burglar\",\"burglary\",\"cheat\",\"convict\",\"conviction\",\"corrupt\",\"corruption\",\"danger\",\"dangerous\",\"illegal\",\"disobediance\",\"immoral\",\"imprisoned\",\"incarceration\",\"inmate\",\"theft\",\"thief\",\"rape\",\"robber\",\"robbery\",\"threatening\",\"vagrant\",\"vagrancy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrt_dict = [\"smart\",\"smarts\",\"smarter\",\"wit\",\"wise\",\"wisdom\",\"intellect\",\"intelligent\",\"intelligence\",\"brilliant\",\"brilliance\",\"brains\",\"clever\",\"cleverness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_dict = [\"simpleness\",\"simplicity\",\"simpleton\",\"dumb\",\"dumbness\",\"fool\",\"foolish\",\"foolishness\",\"mindless\",\"mindlessness\",\"senseless\",\"senselessness\",\"stupid\",\"stupidity\",\"stupidness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.tsv\",\"w+\") as file_metadata:\n",
    "    file_metadata.write(\"Word\\tCategory\\n\")\n",
    "    for i,word in enumerate(model.wv.index2word[:max_size]):\n",
    "        w2v[i] = model.wv[word]\n",
    "        if(word in african_dict):\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'terms_african'))\n",
    "        elif(word in ind_dict):\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'terms_indian'))\n",
    "        elif(word in brit_dict):\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'terms_caucasian'))\n",
    "        elif(word in crim_dict):\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'terms_criminality'))\n",
    "        elif(word in smrt_dict):\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'terms_smart'))\n",
    "        elif(word in dumb_dict):\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'terms_dumb'))\n",
    "        else:\n",
    "            file_metadata.write(\"%s\\t%s\\n\" % (word,'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.03846812e+00,  2.50827193e+00,  4.16977048e-01, ...,\n",
       "        -3.06430817e+00, -1.03770852e+00,  1.49504697e+00],\n",
       "       [-8.28388214e-01,  5.27804613e-01,  3.30885410e+00, ...,\n",
       "        -1.12653464e-01,  3.92413974e+00,  1.20077990e-01],\n",
       "       [ 3.60598505e-01,  1.36050177e+00, -2.08310574e-01, ...,\n",
       "        -3.76490206e-01, -5.32922924e-01,  1.65610766e+00],\n",
       "       ...,\n",
       "       [-2.48545338e-03,  3.17125395e-03, -3.72075569e-03, ...,\n",
       "         3.82435531e-03, -7.62992480e-04,  4.36963513e-03],\n",
       "       [-4.64878278e-03,  3.92424222e-03,  4.34570434e-03, ...,\n",
       "         2.11275392e-03,  2.60445382e-03,  1.95318297e-03],\n",
       "       [-3.21174995e-03, -2.71514873e-03,  4.67777951e-03, ...,\n",
       "        -1.40409265e-03,  7.27262450e-05,  5.06083306e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us create a 2D tensor called embedding that holds our embeddings.\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.Variable(w2v, trainable=False, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us create an object to Saver class which is actually used to \n",
    "#save and restore variables to and from our checkpoints\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using file writer, we can save our summaries and events to our event file.\n",
    "writer = tf.summary.FileWriter(path, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding into projector\n",
    "config = projector.ProjectorConfig()\n",
    "embed = config.embeddings.add()\n",
    "embed.tensor_name = 'embedding'\n",
    "embed.metadata_path = 'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorboard/model.ckpt-788791'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the width and height of a single thumbnail.\n",
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "saver.save(sess, path+'/model.ckpt', global_step=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
